{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube Video Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env data\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Access Groq API Key\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x79f6b69e78f0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x79f6b68043b0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create gemma model\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "def extract_video_id(video_url):\n",
    "    \"\"\"\n",
    "    Extract the video ID from the YouTube URL.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(video_url)\n",
    "    video_id = parse_qs(parsed_url.query).get(\"v\", [None])[0]\n",
    "    if not video_id:\n",
    "        raise ValueError(\"Invalid YouTube URL: Unable to extract video ID.\")\n",
    "    return video_id\n",
    "\n",
    "\n",
    "def summarize_youtube_video(video_url):\n",
    "    try:\n",
    "        # Extract video ID\n",
    "        video_id = extract_video_id(video_url)\n",
    "\n",
    "        # Initialize the YouTube loader\n",
    "        loader = YoutubeLoader(video_id, add_video_info=False)\n",
    "\n",
    "        # Load documents (transcript and metadata)\n",
    "        docs = loader.load()\n",
    "\n",
    "        # Load the summarization chain\n",
    "        chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "        # Generate summary\n",
    "        summary = chain.run(docs)\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This video explains the differences between AI, Machine Learning (ML), Deep Learning (DL), and Generative AI. \n",
      "\n",
      "**Key takeaways:**\n",
      "\n",
      "* **AI** is the broad goal of creating machines that can perform tasks like humans.\n",
      "* **ML** is a subset of AI that uses statistical tools to learn from data and make predictions. It's used for tasks like classification and regression.\n",
      "* **DL** is a subset of ML that uses artificial neural networks inspired by the human brain to learn complex patterns. It excels in areas like computer vision and natural language processing.\n",
      "* **Generative AI**, a subset of DL, focuses on creating new content like text, images, and videos based on the patterns it learned from massive datasets.\n",
      "\n",
      "The video highlights popular generative AI models like GPT-4, LaMDA, and DALL-E, and discusses the concept of \"foundation models\" which are pre-trained on vast amounts of data and can be fine-tuned for specific tasks.\n",
      "\n",
      "It also introduces LangChain, a framework for building applications using LLMs, and mentions Stability AI's work on large image models.  \n",
      "\n",
      "\n",
      "Essentially, the video provides a clear and concise overview of the evolution and applications of AI, with a focus on the exciting advancements in generative AI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=X7Zd4VyUgL0\"\n",
    "\n",
    "# Summarize the video\n",
    "summary = summarize_youtube_video(video_url)\n",
    "\n",
    "if summary:\n",
    "    print(summary)\n",
    "else:\n",
    "    print(\"Failed to summarize the video.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\n    Provide the summary of the following content in 300 wards:\\n    Contents: {text}\\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    Provide the summary of the following content in 300 wards:\n",
    "    Contents: {text}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=prompt_template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "def extract_video_id(video_url):\n",
    "    \"\"\"\n",
    "    Extract the video ID from the YouTube URL.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(video_url)\n",
    "    video_id = parse_qs(parsed_url.query).get(\"v\", [None])[0]\n",
    "    if not video_id:\n",
    "        raise ValueError(\"Invalid YouTube URL: Unable to extract video ID.\")\n",
    "    return video_id\n",
    "\n",
    "\n",
    "def summarize_youtube_video(video_url):\n",
    "    try:\n",
    "        # Extract video ID\n",
    "        video_id = extract_video_id(video_url)\n",
    "\n",
    "        # Initialize the YouTube loader\n",
    "        loader = YoutubeLoader(video_id, add_video_info=False)\n",
    "\n",
    "        # Load documents (transcript and metadata)\n",
    "        docs = loader.load()\n",
    "\n",
    "        # Load the summarization chain\n",
    "        chain = load_summarize_chain(llm=llm, chain_type=\"stuff\", prompt=prompt)\n",
    "\n",
    "        # Generate summary\n",
    "        summary = chain.run(docs)\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This video by Kush Naak provides a comprehensive overview of Artificial Intelligence (AI), focusing on the distinctions between AI, Machine Learning (ML), Deep Learning (DL), and Generative AI.\n",
      "\n",
      "**Here's a summary:**\n",
      "\n",
      "* **AI:** The overarching concept of creating intelligent systems capable of performing tasks without human intervention. Examples include Netflix's recommendation system and self-driving cars.\n",
      "* **Machine Learning (ML):** A subset of AI that utilizes statistical tools and algorithms to learn patterns from data, enabling tasks like prediction, forecasting, and visualization.\n",
      "* **Deep Learning (DL):** A specialized field within ML inspired by the structure of the human brain, employing multi-layered neural networks to process complex data. Key areas include:\n",
      "    * **Artificial Neural Networks (ANNs):** General-purpose neural networks for various tasks.\n",
      "    * **Convolutional Neural Networks (CNNs):** Specialized for computer vision tasks like object detection.\n",
      "    * **Recurrent Neural Networks (RNNs) and Variants:** Designed for processing sequential data, such as text and time series.\n",
      "* **Generative AI:** A subset of DL focused on creating new content based on learned patterns. It utilizes foundation models (pre-trained on vast datasets) like:\n",
      "    * **Large Language Models (LLMs):** Generate text, translate languages, write different kinds of creative content, and answer questions in an informative way. Examples include OpenAI's GPT-4, Meta's Llama 2, Google's Gemini, and Anthropic's Claude 3.\n",
      "    * **Large Image Models:** Generate images and videos from text descriptions.\n",
      "* **LangChain:** A framework that enables developers to build applications using LLMs, facilitating tasks like question answering, code generation, and chatbot development.\n",
      "\n",
      "\n",
      "The video emphasizes the ongoing race among companies to develop the best foundation models, with open-source models gaining traction alongside proprietary solutions. The potential applications of generative AI are vast, spanning various industries and use cases.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=X7Zd4VyUgL0\"\n",
    "\n",
    "# Summarize the video\n",
    "summary = summarize_youtube_video(video_url)\n",
    "\n",
    "if summary:\n",
    "    print(summary)\n",
    "else:\n",
    "    print(\"Failed to summarize the video.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAIPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
