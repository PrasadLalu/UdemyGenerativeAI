{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace x Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load env data\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, temperature=0.7, model_kwargs={\"max_length\": 150})\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nGenerative AI is a type of artificial intelligence that uses algorithms to create new content, such as images, text, music, and even video. It works by learning patterns from a large dataset and using that knowledge to generate new, original content that is similar to the data it was trained on.\\n\\nThere are different types of generative AI, including:\\n\\n1. Markov Chains: A type of statistical model that uses probabilities to predict the next state based on the current state.\\n2. Recurrent Neural Networks (RNNs): A type of artificial neural network that is designed to recognize patterns in sequences of data, such as text or speech.\\n3. Generative Adversarial Networks (GANs): A type of neural network that consists of two parts: a generator and a discriminator. The generator creates new content, while the discriminator tries to distinguish between the generated content and real data.\\n4. Variational Autoencoders (VAEs): A type of neural network that learns a probabilistic distribution of the data it was trained on and uses that distribution to generate new, original content.\\n\\nGenerative AI is being used in a variety of fields, including art, music, and natural language processing. It has the potential to revolutionize industries such as advertising, entertainment, and finance by automating the creation of new content. However, it also raises ethical and privacy concerns, as the AI may generate content that infringes on copyrights or invades privacy.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is generative ai?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMachine learning is a subset of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves.\\n\\nThe process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly.\\n\\nThere are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.\\n\\n1. Supervised learning: In supervised learning, we have a set of labeled data where each input data has a corresponding output value. The machine learning algorithm learns to map inputs to outputs by finding patterns in the data. The goal is to learn a function that can accurately predict the output for new inputs that it has not seen before.\\n\\n2. Unsupervised learning: In unsupervised learning, we have a set of unlabeled data and the goal is to find patterns or structure in the data without any prior knowledge of what the data represents. The algorithm learns to group similar data points together and identify any underlying relationships between them.\\n\\n3. Reinforcement learning: In reinforcement learning, the machine learning algorithm learns to make decisions by interacting with its environment and receiving rewards or punishments based on its actions. The goal is to learn a policy that maximizes the cumulative reward over time.\\n\\nMachine learning is used in a wide range of applications, including image and speech recognition, natural language processing, fraud detection, recommendation systems, and autonomous vehicles. It has the potential to revolutionize many industries and make our lives easier and more convenient in the future.\\n\\nMachine learning has many benefits, including:\\n\\n1. Improved accuracy and precision: Machine learning algorithms can analyze large amounts of data and make decisions based on patterns and trends that humans may not be able to see.\\n\\n2. Reduced human error: By automating repetitive and tedious tasks, machine learning can reduce the risk of human error and improve the overall accuracy of decisions.\\n\\n3. Increased efficiency: Machine learning can process large amounts of data quickly and efficiently, allowing businesses to make faster and more informed decisions.\\n\\n4. Improved customer experiences: Machine learning'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='google/gemma-2-2b-it', temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150}, model='google/gemma-2-2b-it', client=<InferenceClient(model='google/gemma-2-2b-it', timeout=120)>, async_client=<InferenceClient(model='google/gemma-2-2b-it', timeout=120)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id = \"google/gemma-2-2b-it\"\n",
    "model = HuggingFaceEndpoint(repo_id=repo_id, temperature=0.7, model_kwargs={\"max_length\": 150})\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMachine learning (ML) is a branch of artificial intelligence (AI) that focuses on enabling computers to learn from data without being explicitly programmed. Instead of relying on specific instructions, ML algorithms analyze data, identify patterns, and make predictions or decisions based on that knowledge.\\n\\nHere\\'s a breakdown:\\n\\n**Key Concepts:**\\n\\n* **Data:** ML algorithms require large datasets to learn from.\\n* **Algorithms:** These are mathematical models that define how the data is processed and analyzed.\\n* **Training:** The process of feeding the algorithm with data to learn patterns and relationships.\\n* **Prediction:** Using the trained algorithm to make predictions about new, unseen data.\\n\\n**How it works:**\\n\\n1. **Data Collection:** Gather relevant data relevant to the problem you want to solve.\\n2. **Data Preprocessing:** Clean and prepare the data for analysis.\\n3. **Algorithm Selection:** Choose an algorithm suitable for the task (classification, regression, clustering, etc.).\\n4. **Training:** Feed the algorithm with labeled data (e.g., images with labels \"cat\" or \"dog\"). \\n5. **Evaluation:** Test the trained algorithm\\'s performance on unseen data.\\n6. **Deployment:** Integrate the trained model into a system for making predictions on new data.\\n\\n**Types of Machine Learning:**\\n\\n* **Supervised Learning:** The algorithm is trained on labeled data (input-output pairs). Examples: image classification, spam detection.\\n* **Unsupervised Learning:** The algorithm is trained on unlabeled data and discovers patterns without guidance. Examples: customer segmentation, anomaly detection.\\n* **Reinforcement Learning:** The algorithm learns through trial and error, receiving rewards for good decisions and penalties for bad ones. Examples: game playing, robotics.\\n\\n**Applications:**\\n\\nMachine learning is used in various fields, including:\\n\\n* **Healthcare:** Diagnosing diseases, predicting patient outcomes.\\n* **Finance:** Fraud detection, risk assessment, stock trading.\\n* **E-commerce:** Recommender systems, personalized shopping experiences.\\n* **Manufacturing:** Predictive maintenance, quality control.\\n* **Social Media:** Content filtering, spam detection.\\n\\n**Benefits:**\\n\\n* **Automated learning:** Reduces manual data analysis and decision-making.\\n* **Improved accuracy:** Often surpasses human performance in specific tasks.\\n* **Personalization:** Creates tailored experiences for users based on data analysis.\\n* **Scalability:** Can handle massive datasets and complex problems.\\n\\n\\n**Challenges:**\\n\\n*'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace with Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template=\"\\n    Questions: {question}\\n    Answer: Let's things step by step\\n\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Questions: {question}\n",
    "    Answer: Let's things step by step\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_335226/2746620265.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=model, prompt=prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is generative ai?', 'text': \"    1.  **Artificial intelligence (AI):**  Think of AI as machines that can learn and problem-solve like humans. They can analyze data, make predictions, and even create new things. \\n    2. **Generative AI:** Now, generative AI takes things a step further. It's a type of AI that focuses on creating new content, whether it's images, text, music, code, or even 3D models. \\n    3. **How it Works:** Generative AI models are trained on vast amounts of data.  Imagine showing a model thousands of photos of cats and dogs. Over time, it learns the patterns and characteristics of each type of animal. \\n    4. **Examples:**  Here are some popular examples: \\n        * **ChatGPT:**  This AI can write stories, poems, articles, and even code! \\n        * **DALL-E 2:**  This model generates stunning images from text prompts. \\n        * **Jukebox:**  This AI can create original music in different styles.\\n        * **GitHub Copilot:**  This AI assists programmers by suggesting code completions. \\n\\n**In a nutshell:** Generative AI is like having a super smart computer that can create new things based on what it has learned. \\n\\n**Let me know if you'd like to learn more about a specific type of generative AI!** \\n\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=model, prompt=prompt)\n",
    "response = chain.invoke({ \"question\": \"What is generative ai?\" })\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Who won the cricket world cup 2011?', 'text': \"    1. **Check the teams that played in the 2011 Cricket World Cup:** The 2011 Cricket World Cup saw 14 teams compete.\\n    2. **Identify the winning team:**  India won the 2011 Cricket World Cup.\\n\\n**Why is this approach helpful?**\\n\\n* **Clarity:** It breaks down the question into smaller, understandable steps.\\n* **Logic:** It guides the reader through the logical process of finding the answer.\\n* **Transparency:** It makes the reasoning behind the answer clear.\\n* **Ease of comprehension:** This approach makes it easier for someone who is learning to understand the process of answering complex questions. \\n\\n**Note:** You can adapt this approach for any question, but it's particularly helpful when the answer involves multiple steps.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({ \"question\": \"Who won the cricket world cup 2011?\" })\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Who won the cricket world cup 2011?',\n",
       " 'text': '\\n    Step 1: Define the question\\n    Question: Who won the cricket world cup in the year 2011?\\n\\n    Step 2: Identify the required information\\n    Required Information: The name of the team that won the Cricket World Cup in the year 2011.\\n\\n    Step 3: Search for the answer\\n    Answer: The team that won the Cricket World Cup in the year 2011 was India.\\n\\n    Final Answer: India won the Cricket World Cup in the year 2011.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.invoke({ \"question\": \"Who won the cricket world cup 2011?\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JanGenEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
