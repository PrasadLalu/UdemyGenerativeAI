{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Website Text Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env data\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Access Groq API Key\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x710453a0b3e0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x710453a0be90>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create gemma model\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\n    Provide the summary of the following content in 300 wards:\\n    Contents: {text}\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    Provide the summary of the following content in 300 wards:\n",
    "    Contents: {text}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=prompt_template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/laluprasadmahato@ADCNST.COM/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "/home/laluprasadmahato@ADCNST.COM/Desktop/Projects/Generative-AI-Projects-2025/GenAIPro/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'python.langchain.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text describes various methods for text summarization using large language models (LLMs). \n",
      "\n",
      "The tutorial focuses on two primary techniques: \"Stuff\" and \"Map-Reduce\".\n",
      "\n",
      "**Stuff** directly feeds all documents into a single prompt, suitable for LLMs with large context windows.\n",
      "\n",
      "**Map-Reduce** breaks down documents into smaller chunks, summarizes each individually, and then combines the summaries into a final document.\n",
      "\n",
      "The tutorial emphasizes the use of `LangChain`, a framework for building applications with LLMs. It highlights the use of `LangGraph`, a tool for orchestrating complex LLM tasks.\n",
      "\n",
      "The tutorial provides code examples using OpenAI's GPT-4o-mini.\n",
      "\n",
      "**Key takeaways:**\n",
      "\n",
      "* **LangChain and LangGraph are powerful tools for text summarization with LLMs.\n",
      "* **Stuff and Map-Reduce are effective summarization techniques, each with its strengths.\n",
      "* **Customizability is key to fine-tuning your summarization process.\n",
      "* **LangChain and LangGraph offer more than just summarization, enabling broader LLM applications.\n",
      "\n",
      "\n",
      "Let me know if you have any other questions. I'm here to help!\n",
      "\n",
      "Let me know if you have any other questions.\n",
      "\n",
      "300-word summary of the provided text.\n",
      "This text provides a concise introduction to text summarization using large language models (LLMs) through the LangChain framework.\n",
      "\n",
      "The tutorial focuses on two main summarization techniques:\n",
      "\n",
      "* **Stuff:\n",
      "\n",
      "    this method directly feeds all documents into a single LLM prompt, best suited for LLMs with large context windows.\n",
      "\n",
      "* **Map-Reduce:\n",
      "\n",
      "    this approach breaks down documents into smaller chunks, summarizes each individually, and then combines the summaries,\n",
      "\n",
      "The tutorial emphasizes the use of `LangChain` for building LLM applications. It highlights the use of `LangGraph, a tool for orchestrating complex LLM tasks.\n",
      "\n",
      "The tutorial provides code examples using OpenAI's GPT-4o-mini.\n",
      "\n",
      "**Key takeaways:**\n",
      "\n",
      "* **LangChain and LangGraph are powerful tools for text summarization with LLMs.\n",
      "* **Stuff and Map-Reduce are effective summarization techniques, each with its strengths.\n",
      "* **Customizability is key to fine-tuning your summarization process.\n",
      "* **LangChain offers more than just summarization, enabling broader LLM applications.\n",
      "\n",
      "Let me know if you have any other questions. I'm here to help!\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "generic_url = \"https://python.langchain.com/docs/tutorials/summarization/\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36\"}\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=[generic_url], ssl_verify=False, headers=headers)\n",
    "      \n",
    "# Load docs              \n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "# Summarize the text\n",
    "chain = load_summarize_chain(llm=llm, chain_type=\"stuff\", prompt=prompt)\n",
    "output_summary = chain.run(docs)\n",
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAIPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
