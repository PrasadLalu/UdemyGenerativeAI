{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load env data\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x7e7f191c5640> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7e7f191c73e0> root_client=<openai.OpenAI object at 0x7e7f2833e360> root_async_client=<openai.AsyncOpenAI object at 0x7e7f191c56a0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a category of artificial intelligence systems designed to generate data that mimics or replicates the characteristics of real-world data. These systems use machine learning models, particularly deep learning techniques, to produce various types of content, including text, images, music, and even code. The primary goal of generative AI is to create new, synthetic instances that are indistinguishable from authentic data.\\n\\nKey components of generative AI include:\\n\\n1. **Deep Learning Models**: Generative AI often utilizes neural networks, especially architectures like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models. These architectures learn patterns and structures within the data to generate realistic outputs.\\n\\n2. **Generative Adversarial Networks (GANs)**: These consist of two neural networks, a generator and a discriminator, pitted against each other. The generator creates fake data, while the discriminator evaluates its authenticity. Through this adversarial process, the generator improves its ability to produce convincing data.\\n\\n3. **Variational Autoencoders (VAEs)**: These models learn to encode input data into a lower-dimensional latent space and then decode it back, generating new data samples by sampling from this latent space.\\n\\n4. **Transformer Models**: Models like GPT (Generative Pre-trained Transformer) have revolutionized text generation by using large-scale pre-training on diverse datasets, enabling them to generate coherent and contextually relevant text.\\n\\nApplications of generative AI are diverse and expanding, including:\\n\\n- **Content Creation**: Automating the creation of articles, stories, and even creative writing.\\n- **Art and Design**: Generating artwork, design prototypes, and visual content.\\n- **Gaming**: Creating realistic characters, environments, and scenarios.\\n- **Medicine**: Synthesizing medical images for training and research.\\n- **Data Augmentation**: Enhancing training datasets by generating additional samples.\\n\\nGenerative AI has the potential to significantly impact various industries by automating and enhancing creative processes. However, it also raises ethical and regulatory challenges, such as the potential for misuse in creating deepfakes or misinformation, necessitating careful consideration and management.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 440, 'prompt_tokens': 13, 'total_tokens': 453, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-1ff89198-0da0-4b2d-9096-53c9055290e0-0', usage_metadata={'input_tokens': 13, 'output_tokens': 440, 'total_tokens': 453, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke('What is Generative AI?')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative AI refers to a category of artificial intelligence systems designed to generate data that mimics or replicates the characteristics of real-world data. These systems use machine learning models, particularly deep learning techniques, to produce various types of content, including text, images, music, and even code. The primary goal of generative AI is to create new, synthetic instances that are indistinguishable from authentic data.\\n\\nKey components of generative AI include:\\n\\n1. **Deep Learning Models**: Generative AI often utilizes neural networks, especially architectures like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models. These architectures learn patterns and structures within the data to generate realistic outputs.\\n\\n2. **Generative Adversarial Networks (GANs)**: These consist of two neural networks, a generator and a discriminator, pitted against each other. The generator creates fake data, while the discriminator evaluates its authenticity. Through this adversarial process, the generator improves its ability to produce convincing data.\\n\\n3. **Variational Autoencoders (VAEs)**: These models learn to encode input data into a lower-dimensional latent space and then decode it back, generating new data samples by sampling from this latent space.\\n\\n4. **Transformer Models**: Models like GPT (Generative Pre-trained Transformer) have revolutionized text generation by using large-scale pre-training on diverse datasets, enabling them to generate coherent and contextually relevant text.\\n\\nApplications of generative AI are diverse and expanding, including:\\n\\n- **Content Creation**: Automating the creation of articles, stories, and even creative writing.\\n- **Art and Design**: Generating artwork, design prototypes, and visual content.\\n- **Gaming**: Creating realistic characters, environments, and scenarios.\\n- **Medicine**: Synthesizing medical images for training and research.\\n- **Data Augmentation**: Enhancing training datasets by generating additional samples.\\n\\nGenerative AI has the potential to significantly impact various industries by automating and enhancing creative processes. However, it also raises ethical and regulatory challenges, such as the potential for misuse in creating deepfakes or misinformation, necessitating careful consideration and management.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital city of India is New Delhi.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke('What is the capital city on India?')\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI ChatPrompt Template Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ChatPrompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You are an expert AI Engineer. Provide me answer based on question'),\n",
    "        ('user', '{prompt_input}')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['prompt_input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['prompt_input'], input_types={}, partial_variables={}, template='{prompt_input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital city of India is New Delhi.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 32, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-af4f59d7-191a-43ac-b140-4d45526fa0af-0', usage_metadata={'input_tokens': 32, 'output_tokens': 10, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a chain\n",
    "chain = prompt | llm\n",
    "result = chain.invoke('What is the capital city of India?')\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangSmith is a platform that enhances the development and deployment of applications built with large language models (LLMs). It provides tools and features that allow developers to effectively test, evaluate, and monitor their language model-driven applications. LangSmith typically offers capabilities for prompt engineering, enabling developers to craft and iterate on prompts to optimize model performance. Additionally, it often includes analytics and logging features to track model interactions and performance metrics, helping developers gain insights into how their applications are being used and how they can be improved. This kind of platform is particularly useful for those looking to refine their LLM applications for better accuracy, reliability, and user experience.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 31, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-f542df3d-37ad-41b9-8c26-1a38c7840bee-0', usage_metadata={'input_tokens': 31, 'output_tokens': 128, 'total_tokens': 159, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a chain\n",
    "chain = prompt | llm\n",
    "result = chain.invoke('Tell me something about LangSmith?')\n",
    "result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI ChatPrompt Template Chain with Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith is a platform developed by LangChain that provides tools and support for building, monitoring, and continuously improving applications powered by language models. It focuses on helping developers enhance the performance, reliability, and user experience of their AI-driven applications. LangSmith offers features such as real-time monitoring, debugging, and analytics to track how language models are performing in production. It also provides insights into user interactions to help developers fine-tune their applications and ensure they meet the desired objectives. With LangSmith, developers can iterate on their applications efficiently, addressing issues and optimizing performance based on concrete data and feedback.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a chain with output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "outputParser = StrOutputParser()\n",
    "chain = prompt | llm | outputParser\n",
    "\n",
    "result = chain.invoke('Tell me something about LangSmith?')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JanGenEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
